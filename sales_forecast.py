# ğŸ“¦ Production Python Script for GitHub Actions - Sales Forecast Model

import pandas as pd
import requests
import time
import numpy as np
import os
from datetime import datetime, timedelta
import xgboost as xgb
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error
from google.oauth2.service_account import Credentials
import gspread
from gspread_dataframe import set_with_dataframe

# === è¨­å®š Google Sheet ===
SHEET_ID = "1ufAI8OY64NKrpLS17qlYuOX5HWgGlCyZsgPRC-NfQJI"
SHEET_NAME = "sheet1"
REPORT_SHEET_NAME = "report"
NEW_SKU_SHEET_NAME = "new_skus"
MODEL_DESCRIPTION_SHEET_NAME = "model_description"

# === å¾ç’°å¢ƒè®Šæ•¸è®€å– Slack Webhook URL ===
SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL")

# === Functionï¼šç™¼é€ Slack é€šçŸ¥ ===
def send_slack_message(message):
    if not SLACK_WEBHOOK_URL:
        print("âš ï¸ Slack Webhook URL æœªè¨­ç½®ï¼Œç•¥éé€šçŸ¥ã€‚")
        return
    payload = {"text": message}
    try:
        requests.post(SLACK_WEBHOOK_URL, json=payload)
    except Exception as e:
        print(f"âš ï¸ Slack ç™¼é€å¤±æ•—ï¼š{e}")

# === Functionï¼šAPI é‡è©¦æ©Ÿåˆ¶ ===
def fetch_data_with_retry(url, max_retries=3):
    for attempt in range(max_retries):
        try:
            response = requests.get(url)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"âš ï¸ API å¤±æ•— {attempt + 1}/{max_retries} æ¬¡: {e}")
            time.sleep(2)
    send_slack_message(f"ğŸš¨ [é æ¸¬ç³»çµ±] API è³‡æ–™å–å¾—å¤±æ•—ï¼š{url}")
    raise Exception(f"ğŸš¨ API å¤±æ•—è¶…é {max_retries} æ¬¡ï¼š{url}")

# === Functionï¼šæ¬„ä½é˜²å‘† ===
def ensure_columns(df, columns):
    for col in columns:
        if col not in df.columns:
            print(f"âš ï¸ DataFrame ç¼ºå°‘æ¬„ä½ï¼š{col}ï¼Œè‡ªå‹•è£œ 0")
            df[col] = 0
    return df

# === Functionï¼šå¯«å…¥ Google Sheet ===
def write_to_gsheet(df, sheet_id, sheet_name):
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = Credentials.from_service_account_file("besparks-service-account.json", scopes=scope)
    client = gspread.authorize(creds)
    sheet = client.open_by_key(sheet_id)
    worksheet = sheet.worksheet(sheet_name)
    worksheet.clear()
    set_with_dataframe(worksheet, df)

try:
    print("ğŸ“¥ é–‹å§‹è®€å– API è³‡æ–™...")
    sales_data = fetch_data_with_retry("https://api.besparks.co/api:074LNDs2/data/slaes_history")
    product_data = fetch_data_with_retry("https://api.besparks.co/api:074LNDs2/data/product_info")
    forecast_data = fetch_data_with_retry("https://api.besparks.co/api:074LNDs2/data/forecast")

    sales_df = pd.DataFrame(sales_data)
    product_df = pd.DataFrame(product_data)
    forecast_df = pd.DataFrame(forecast_data)
    sales_df['date'] = pd.to_datetime(sales_df['date'], format='%Y-%m')

    print("âœ… API è³‡æ–™è®€å–å®Œæˆ")

    print("ğŸ§© æ•¸æ“šæ¸…æ´—èˆ‡ç‰¹å¾µå·¥ç¨‹...")
    product_df = ensure_columns(product_df, ['price', 'sku_cost', 'gross_margin'])
    product_df['price'] = pd.to_numeric(product_df.get('price', product_df.get('msrp', 0)), errors='coerce').fillna(0)
    product_df['sku_cost'] = pd.to_numeric(product_df['sku_cost'], errors='coerce').fillna(0)
    product_df['gross_margin'] = product_df['price'] - product_df['sku_cost']

    merged_df = sales_df.merge(product_df, on='sku', how='left', suffixes=('', '_prod'))
    merged_df = ensure_columns(merged_df, ['price_prod', 'sku_cost_prod', 'gross_margin_prod'])
    merged_df['price'] = merged_df['price_prod'].fillna(0)
    merged_df['sku_cost'] = merged_df['sku_cost_prod'].fillna(0)
    merged_df['gross_margin'] = merged_df['gross_margin_prod'].fillna(0)

    merged_df['month'] = merged_df['date'].dt.month
    merged_df['year'] = merged_df['date'].dt.year
    sku_encoder = LabelEncoder()
    merged_df['sku_encoded'] = sku_encoder.fit_transform(merged_df['sku'])

    merged_df = merged_df.sort_values(['sku', 'date'])
    merged_df['prev_1_month_qty'] = merged_df.groupby('sku')['quantity_sold'].shift(1).fillna(0)
    merged_df['rolling_3_month_qty'] = merged_df.groupby('sku')['quantity_sold'].transform(lambda x: x.shift(1).rolling(3, min_periods=1).mean()).fillna(0)
    merged_df['rolling_6_month_qty'] = merged_df.groupby('sku')['quantity_sold'].transform(lambda x: x.shift(1).rolling(6, min_periods=1).mean()).fillna(0)

    feature_columns = ['month', 'year', 'sku_encoded', 'prev_1_month_qty', 'rolling_3_month_qty', 'rolling_6_month_qty', 'price', 'gross_margin']
    for col in feature_columns:
        merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce').fillna(0)

    print("âœ… ç‰¹å¾µå·¥ç¨‹å®Œæˆ")

    print("ğŸ§  é–‹å§‹æ¨¡å‹è¨“ç·´...")
    dtrain = xgb.DMatrix(merged_df[feature_columns], label=merged_df['quantity_sold'])
    params = {'objective': 'reg:squarederror', 'eval_metric': 'rmse'}
    model = xgb.train(params, dtrain, num_boost_round=100)

    preds_train = model.predict(dtrain)
    mae = mean_absolute_error(merged_df['quantity_sold'], preds_train)
    mape = mean_absolute_percentage_error(merged_df['quantity_sold'], preds_train)

    print(f"âœ… æ¨¡å‹è¨“ç·´å®Œæˆï¼ŒMAE: {mae:.2f}, MAPE: {mape:.2%}")

    print("ğŸ”® é æ¸¬æœªä¾†ä¸‰å€‹æœˆ...")
    future_months = [datetime.today() + timedelta(days=30 * i) for i in range(1, 4)]
    future_df = pd.DataFrame({'month': [d.month for d in future_months], 'year': [d.year for d in future_months]})
    future_skus = product_df['sku'].unique()
    future_df = future_df.assign(key=1).merge(pd.DataFrame({'sku': future_skus, 'key': 1}), on='key').drop('key', axis=1)

    sku_mapping = dict(zip(sku_encoder.classes_, sku_encoder.transform(sku_encoder.classes_)))
    future_df['sku_encoded'] = future_df['sku'].map(sku_mapping).fillna(-1).astype(int)

    latest_product_info = product_df[['sku', 'price', 'sku_cost', 'gross_margin']].drop_duplicates('sku')
    future_df = future_df.merge(latest_product_info, on='sku', how='left')

    last_sales = merged_df[merged_df['date'] == merged_df['date'].max()][['sku', 'quantity_sold', 'rolling_3_month_qty', 'rolling_6_month_qty']].drop_duplicates('sku')
    last_sales.rename(columns={'quantity_sold': 'prev_1_month_qty'}, inplace=True)
    future_df = future_df.merge(last_sales, on='sku', how='left')

    future_df = ensure_columns(future_df, feature_columns)
    for col in feature_columns:
        future_df[col] = pd.to_numeric(future_df[col], errors='coerce').fillna(0)

    dfmatrix = xgb.DMatrix(future_df[feature_columns])
    future_df['forecast_qty'] = np.maximum(model.predict(dfmatrix).round().astype(int), 0)

    result = future_df.pivot(index='sku', columns='month', values='forecast_qty').reset_index()
    month_map = {m: f'æœªä¾†{i+1}å€‹æœˆéŠ·å”®é æ¸¬' for i, m in enumerate(result.columns[1:])}
    result.rename(columns=month_map, inplace=True)

    print("ğŸ“ è¼¸å‡º Google Sheet å ±è¡¨...")
    write_to_gsheet(result, SHEET_ID, SHEET_NAME)

    report_df = pd.DataFrame({'æŒ‡æ¨™': ['MAE', 'MAPE'], 'æ•¸å€¼': [mae, mape]})
    write_to_gsheet(report_df, SHEET_ID, REPORT_SHEET_NAME)

    known_skus = set(merged_df['sku'].unique())
    all_skus = set(product_df['sku'].unique())
    new_skus = all_skus - known_skus
    new_sku_df = pd.DataFrame({'æ–°å“ SKU': list(new_skus)})
    write_to_gsheet(new_sku_df, SHEET_ID, NEW_SKU_SHEET_NAME)

    model_description_df = pd.DataFrame({
        'é …ç›®': ['æ¨¡å‹é¡å‹', 'é æ¸¬ç›®æ¨™', 'ä½¿ç”¨ç‰¹å¾µ', 'æ•¸æ“šä¾†æº', 'æº–ç¢ºç‡æŒ‡æ¨™', 'æ¨¡å‹è¨“ç·´æ¬¡æ•¸', 'ç‰¹åˆ¥èªªæ˜'],
        'èªªæ˜': [
            'XGBoost Regressor',
            'SKU æ¯æœˆéŠ·é‡',
            'month, year, sku_encoded, price, gross_margin, éå»1å€‹æœˆéŠ·é‡, æ»¾å‹•3/6å€‹æœˆéŠ·é‡å¹³å‡',
            'APIï¼šsales_history, product_info',
            'MAE / MAPE å·²åœ¨ report åˆ†é ',
            '100 æ¬¡è¿­ä»£ (num_boost_round=100)',
            'SKU ç¶“ LabelEncoder ç·¨ç¢¼ï¼Œåƒ¹æ ¼åŠæ¯›åˆ©ç‚ºä¸»è¦å½±éŸ¿å› å­ä¹‹ä¸€'
        ]
    })
    write_to_gsheet(model_description_df, SHEET_ID, MODEL_DESCRIPTION_SHEET_NAME)

    send_slack_message("âœ… [é æ¸¬ç³»çµ±] æœ€æ–°æœˆä»½éŠ·å”®é æ¸¬å·²å®Œæˆä¸¦ä¸Šå‚³è‡³ Google Sheetï¼")
    print("âœ… é æ¸¬æµç¨‹å·²å®Œæˆï¼Œè«‹æª¢æŸ¥ Google Sheet å ±è¡¨ï¼")

except Exception as e:
    send_slack_message(f"ğŸš¨ [é æ¸¬ç³»çµ±] åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
    print(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
