# ğŸ“¦ å®Œæ•´ Production-Ready Colab ç¨‹å¼ç¢¼ + æ¨¡å‹è©•ä¼°å ±å‘Š + SKU æ¸…å–® + æ¨¡å‹èªªæ˜ + Slack é€šçŸ¥ + API é‡è©¦æ©Ÿåˆ¶ (æ¨¡æ“¬ç‰ˆ)

# === è¼‰å…¥å¥—ä»¶ ===
import pandas as pd
import requests
import time
from datetime import datetime, timedelta
import xgboost as xgb
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error
from google.oauth2.service_account import Credentials
import gspread
from gspread_dataframe import set_with_dataframe

# === è¨­å®š Google Sheet ===
SHEET_ID = "1ufAI8OY64NKrpLS17qlYuOX5HWgGlCyZsgPRC-NfQJI"
SHEET_NAME = "sheet1"
REPORT_SHEET_NAME = "report"
NEW_SKU_SHEET_NAME = "new_skus"
MODEL_DESCRIPTION_SHEET_NAME = "model_description"

# === è¨­å®š Slack Webhook URL ===
SLACK_WEBHOOK_URL = "https://hooks.slack.com/services/xxxx/yyyy/zzzz"  # <-- é€™è£¡æ›æˆä½ çš„ Slack Webhook URL

# === Functionï¼šç™¼é€ Slack é€šçŸ¥ ===
def send_slack_message(message):
    payload = {"text": message}
    try:
        requests.post(SLACK_WEBHOOK_URL, json=payload)
    except Exception as e:
        print(f"âš ï¸ Slack ç™¼é€å¤±æ•—ï¼š{e}")

# === Functionï¼šAPI é‡è©¦æ©Ÿåˆ¶ ===
def fetch_data_with_retry(url, max_retries=3):
    for attempt in range(max_retries):
        try:
            response = requests.get(url)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"âš ï¸ API å¤±æ•— {attempt + 1}/{max_retries} æ¬¡: {e}")
            time.sleep(2)
    send_slack_message(f"ğŸš¨ [é æ¸¬ç³»çµ±] API è³‡æ–™å–å¾—å¤±æ•—ï¼š{url}")
    raise Exception(f"ğŸš¨ API å¤±æ•—è¶…é {max_retries} æ¬¡ï¼š{url}")

# === Functionï¼šæ¬„ä½é˜²å‘† ===
def ensure_columns(df, columns):
    for col in columns:
        if col not in df.columns:
            print(f"âš ï¸ DataFrame ç¼ºå°‘æ¬„ä½ï¼š{col}ï¼Œè‡ªå‹•è£œ 0")
            df[col] = 0
    return df

# === Functionï¼šå¯«å…¥ Google Sheet ===
def write_to_gsheet(df, sheet_id, sheet_name):
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = Credentials.from_service_account_file("besparks-service-account.json", scopes=scope)
    client = gspread.authorize(creds)
    sheet = client.open_by_key(sheet_id)
    worksheet = sheet.worksheet(sheet_name)
    worksheet.clear()
    set_with_dataframe(worksheet, df)

try:
    # === 1. API è³‡æ–™æ‹‰å– ===
    print("ğŸ“¥ è®€å– API è³‡æ–™...")
    sales_url = "https://api.besparks.co/api:074LNDs2/data/slaes_history"
    product_url = "https://api.besparks.co/api:074LNDs2/data/product_info"
    forecast_url = "https://api.besparks.co/api:074LNDs2/data/forecast"

    sales_data = fetch_data_with_retry(sales_url)
    product_data = fetch_data_with_retry(product_url)
    forecast_data = fetch_data_with_retry(forecast_url)

    sales_df = pd.DataFrame(sales_data)
    product_df = pd.DataFrame(product_data)
    forecast_df = pd.DataFrame(forecast_data)

    sales_df['date'] = pd.to_datetime(sales_df['date'], format='%Y-%m')

    print(f"âœ… Sales history ç­†æ•¸ï¼š{len(sales_df)}")
    print(f"âœ… Product info ç­†æ•¸ï¼š{len(product_df)}")

    # === 2. æ•¸æ“šæ¸…æ´— & ç‰¹å¾µå·¥ç¨‹ ===
    print("ğŸ§© æ•¸æ“šæ¸…æ´—èˆ‡ç‰¹å¾µå·¥ç¨‹...")

    product_df = ensure_columns(product_df, ['price', 'sku_cost', 'gross_margin'])
    product_df['price'] = pd.to_numeric(product_df.get('price', product_df.get('msrp', 0)), errors='coerce').fillna(0)
    product_df['sku_cost'] = pd.to_numeric(product_df['sku_cost'], errors='coerce').fillna(0)
    product_df['gross_margin'] = product_df['price'] - product_df['sku_cost']

    merged_df = sales_df.merge(product_df, on='sku', how='left', suffixes=('', '_prod'))
    merged_df = ensure_columns(merged_df, ['price_prod', 'sku_cost_prod', 'gross_margin_prod'])

    merged_df['price'] = merged_df['price_prod'].fillna(0)
    merged_df['sku_cost'] = merged_df['sku_cost_prod'].fillna(0)
    merged_df['gross_margin'] = merged_df['gross_margin_prod'].fillna(0)

    merged_df['month'] = merged_df['date'].dt.month
    merged_df['year'] = merged_df['date'].dt.year
    sku_encoder = LabelEncoder()
    merged_df['sku_encoded'] = sku_encoder.fit_transform(merged_df['sku'])

    merged_df = merged_df.sort_values(['sku', 'date'])
    merged_df['prev_1_month_qty'] = merged_df.groupby('sku')['quantity_sold'].shift(1).fillna(0)
    merged_df['rolling_3_month_qty'] = merged_df.groupby('sku')['quantity_sold'].transform(lambda x: x.shift(1).rolling(3, min_periods=1).mean()).fillna(0)
    merged_df['rolling_6_month_qty'] = merged_df.groupby('sku')['quantity_sold'].transform(lambda x: x.shift(1).rolling(6, min_periods=1).mean()).fillna(0)

    feature_columns = ['month', 'year', 'sku_encoded', 'prev_1_month_qty', 'rolling_3_month_qty', 'rolling_6_month_qty', 'price', 'gross_margin']
    for col in feature_columns:
        merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce').fillna(0)

    features = feature_columns
    target = 'quantity_sold'

    print("âœ… ç‰¹å¾µå·¥ç¨‹å®Œæˆ")

    # === 3. æ¨¡å‹è¨“ç·´ ===
    print("ğŸ§  æ¨¡å‹è¨“ç·´ä¸­...")
    dtrain = xgb.DMatrix(merged_df[features], label=merged_df[target])
    params = {'objective': 'reg:squarederror', 'eval_metric': 'rmse'}
    model = xgb.train(params, dtrain, num_boost_round=100)

    preds_train = model.predict(dtrain)
    mae = mean_absolute_error(merged_df[target], preds_train)
    mape = mean_absolute_percentage_error(merged_df[target], preds_train)
    print(f"âœ… æ¨¡å‹è¨“ç·´å®Œæˆï¼ŒMAE: {mae:.2f}, MAPE: {mape:.2%}")

    # === 4. é æ¸¬æœªä¾†ä¸‰å€‹æœˆ ===
    print("ğŸ”® é æ¸¬æœªä¾†ä¸‰å€‹æœˆ...")

    future_months = [datetime.today() + timedelta(days=30 * i) for i in range(1, 4)]
    future_df = pd.DataFrame({'month': [d.month for d in future_months], 'year': [d.year for d in future_months]})
    future_skus = product_df['sku'].unique()
    future_df = future_df.assign(key=1).merge(pd.DataFrame({'sku': future_skus, 'key': 1}), on='key').drop('key', axis=1)

    sku_mapping = dict(zip(sku_encoder.classes_, sku_encoder.transform(sku_encoder.classes_)))
    future_df['sku_encoded'] = future_df['sku'].map(sku_mapping).fillna(-1).astype(int)

    product_df = ensure_columns(product_df, ['price', 'sku_cost', 'gross_margin'])
    latest_product_info = product_df[['sku', 'price', 'sku_cost', 'gross_margin']].drop_duplicates('sku')
    future_df = future_df.merge(latest_product_info, on='sku', how='left')

    last_sales = merged_df[merged_df['date'] == merged_df['date'].max()][['sku', 'quantity_sold', 'rolling_3_month_qty', 'rolling_6_month_qty']].drop_duplicates('sku')
    last_sales.rename(columns={'quantity_sold': 'prev_1_month_qty'}, inplace=True)
    future_df = future_df.merge(last_sales, on='sku', how='left')

    future_df = ensure_columns(future_df, features)
    for col in features:
        future_df[col] = pd.to_numeric(future_df[col], errors='coerce').fillna(0)

    dfmatrix = xgb.DMatrix(future_df[features])
    future_df['forecast_qty'] = model.predict(dfmatrix).round().astype(int)

    future_df['forecast_qty'] = future_df['forecast_qty'].apply(lambda x: max(x, 0))

    # === 5. æ•´ç†è¼¸å‡ºæ ¼å¼ ===
    print("ğŸ“Š æ•´ç†è¼¸å‡ºæ ¼å¼...")
    result = future_df.pivot(index='sku', columns='month', values='forecast_qty').reset_index()
    month_map = {m: f'æœªä¾†{i+1}å€‹æœˆéŠ·å”®é æ¸¬' for i, m in enumerate(result.columns[1:])}
    result.rename(columns=month_map, inplace=True)
    print(result.head())

    # === 6. è¼¸å‡ºåˆ° Google Sheet ===
    print("ğŸ“ å¯«å…¥ Google Sheet...")
    write_to_gsheet(result, SHEET_ID, SHEET_NAME)

    # === 7. è¼¸å‡ºæ¨¡å‹æ•ˆæœå ±å‘Šåˆ° Google Sheet ===
    print("ğŸ“ å¯«å…¥æ¨¡å‹æ•ˆæœå ±å‘Š...")
    report_df = pd.DataFrame({
        'æŒ‡æ¨™': ['MAE', 'MAPE'],
        'æ•¸å€¼': [mae, mape]
    })
    write_to_gsheet(report_df, SHEET_ID, REPORT_SHEET_NAME)

    # === 8. æ–°å“ SKU æ¸…å–® ===
    print("ğŸ§¾ è¼¸å‡ºæ–°å“ SKU æ¸…å–®...")
    known_skus = set(merged_df['sku'].unique())
    all_skus = set(product_df['sku'].unique())
    new_skus = all_skus - known_skus
    new_sku_df = pd.DataFrame({'æ–°å“ SKU': list(new_skus)})
    write_to_gsheet(new_sku_df, SHEET_ID, NEW_SKU_SHEET_NAME)

    # === 9. è¼¸å‡ºæ¨¡å‹èªªæ˜æ–‡ä»¶åˆ° Google Sheet ===
    print("ğŸ§¾ è¼¸å‡ºæ¨¡å‹èªªæ˜æ–‡ä»¶...")
    model_description_df = pd.DataFrame({
        'é …ç›®': [
            'æ¨¡å‹é¡å‹',
            'é æ¸¬ç›®æ¨™',
            'ä½¿ç”¨ç‰¹å¾µ',
            'æ•¸æ“šä¾†æº',
            'æº–ç¢ºç‡æŒ‡æ¨™',
            'æ¨¡å‹è¨“ç·´æ¬¡æ•¸',
            'ç‰¹åˆ¥èªªæ˜'
        ],
        'èªªæ˜': [
            'XGBoost Regressor',
            'SKU æ¯æœˆéŠ·é‡',
            'month, year, sku_encoded, price, gross_margin, éå»1å€‹æœˆéŠ·é‡, æ»¾å‹•3/6å€‹æœˆéŠ·é‡å¹³å‡',
            'APIï¼šsales_history, product_info',
            'MAE / MAPE å·²åœ¨ report åˆ†é ',
            '100 æ¬¡è¿­ä»£ (num_boost_round=100)',
            'SKU ç¶“ LabelEncoder ç·¨ç¢¼ï¼Œåƒ¹æ ¼åŠæ¯›åˆ©ç‚ºä¸»è¦å½±éŸ¿å› å­ä¹‹ä¸€'
        ]
    })
    write_to_gsheet(model_description_df, SHEET_ID, MODEL_DESCRIPTION_SHEET_NAME)

    send_slack_message("âœ… [é æ¸¬ç³»çµ±] æœ€æ–°æœˆä»½éŠ·å”®é æ¸¬å·²å®Œæˆä¸¦ä¸Šå‚³è‡³ Google Sheetï¼")
    print("âœ… é æ¸¬æµç¨‹å·²å®Œæˆï¼Œè«‹æª¢æŸ¥ Google Sheet å ±è¡¨ï¼")

except Exception as e:
    send_slack_message(f"ğŸš¨ [é æ¸¬ç³»çµ±] åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
    print(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
